{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio Style Transfer_Objective evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24gM4rgUKI5Y"
      },
      "source": [
        "# Set-Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpGl735zKDh4"
      },
      "source": [
        "!pip install audiosegment\n",
        "!pip install soundfile \n",
        "!pip install fastdtw\n",
        "!pip install scikit-bio\n",
        "!pip uninstall future\n",
        "!pip install future==0.13.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCWRrKrUKH1x"
      },
      "source": [
        "#Connecting Drive to save model checkpoints during training and to use custom data, uncomment if needed\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/\"My Drive\"/\"Audio-Style-Transfer\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhKZD6bjEM5L"
      },
      "source": [
        "import os, time\n",
        "import librosa\n",
        "import librosa.display\n",
        "import math \n",
        "import skbio\n",
        "import itertools\n",
        "\n",
        "import soundfile as sf\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd\n",
        "\n",
        "from scipy.spatial.distance import euclidean, cosine\n",
        "from fastdtw import fastdtw\n",
        "from glob import glob\n",
        "from nltk import ngrams\n",
        "from shutil import copyfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbL4o0WqJVnU"
      },
      "source": [
        "# Read audio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmlEcq93Mf1U"
      },
      "source": [
        "#Hyperparameters\n",
        "\n",
        "hop=192     #hop size (window size = 6*hop)\n",
        "sr=16000     #sampling rate\n",
        "min_level_db=-100     #reference values to normalize data\n",
        "ref_level_db=20\n",
        "\n",
        "shape=64     #length of time axis of split specrograms to feed to generator            \n",
        "vec_len=128     #length of vector generated by siamese vector\n",
        "bs = 16     #batch size\n",
        "delta = 2     #constant for siamese loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYdtvRC2JYhD"
      },
      "source": [
        "def audio_array(path, sr=16000): \n",
        "    \"\"\"\n",
        "        path: \"Notifications/notificationN/\n",
        "    \"\"\"\n",
        "    x = []\n",
        "    paths = sorted(glob(path))\n",
        "    for path in paths:\n",
        "        a, _ = librosa.load(path+'/A.wav', sr=sr)\n",
        "        ab, _ = librosa.load(path+'/AB.wav', sr=sr)\n",
        "        x += [np.stack([a, ab])]\n",
        "    return x, paths  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZLxGkxhJZsw"
      },
      "source": [
        "samples, paths = audio_array(path=\"Evaluation/guitar-transfer/Notifications/*\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uP6btzBK8il"
      },
      "source": [
        "# Melody preservation evaluation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL6Hd3-pqzbW"
      },
      "source": [
        "## Pitch similarity score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEnRYsJuZmqk"
      },
      "source": [
        "Source : https://julian-urbano.info/files/publications/009-using-shape-music-compute-similarity-between-symbolic-musical-pieces.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So32qJOAqxKJ"
      },
      "source": [
        "def compute_spans(pitches):\n",
        "    \"\"\"\n",
        "        pitches : pitches[f, t] contains instantaneous frequency at bin f, time t, take value 0 at bins of non-maximal magnitude.\n",
        "    \"\"\"\n",
        "    n = 4\n",
        "    max_freqs = np.max(pitches, axis=0) \n",
        "    quad_grams = [max_freqs[t:t+n] for t in range(max_freqs.shape[0]-n)]\n",
        "    f_spans = [np.array([b-a, c-a, d-a]) for i in range(len(quad_grams)) for a, b, c, d in zip(quad_grams[i], quad_grams[i][1:], quad_grams[i][2:], quad_grams[i][3:])]\n",
        "    return np.array(f_spans)\n",
        "\n",
        "def local_matching(source_spans, target_spans):\n",
        "    scores = []\n",
        "    alphabet = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V', 'B', 'Z', 'X', '*']\n",
        "    for src, tgt in zip(source_spans, target_spans):\n",
        "        # extract unique values from spans \n",
        "        src_values = np.sort(np.unique(src)) \n",
        "        tgt_values = np.sort(np.unique(tgt))\n",
        "        values = sorted(np.unique(np.concatenate([src_values, tgt_values])))\n",
        "        values = values+[0]*(len(alphabet)-len(values))\n",
        "        # mapping between protein names (alphabet) and values (0 padded)\n",
        "        alphabet_value_map = {a:v for a, v in zip(alphabet, values)}\n",
        "        value_alphabet_map = {v:a for v, a in zip(values, alphabet)}\n",
        "        # encode sequences for alignment\n",
        "        src = ''.join([value_alphabet_map[v] for v in src])\n",
        "        tgt = ''.join([value_alphabet_map[v] for v in tgt])\n",
        "        src = skbio.sequence.Protein(src)\n",
        "        tgt = skbio.sequence.Protein(tgt)\n",
        "        # normalize\n",
        "        max = np.max([abs(v1 - v2) for v1 in values for v2 in values]) \n",
        "        # compute scoring matrix\n",
        "        if max == 0: # in this case source and target spans are identical\n",
        "            substitution_matrix = {a1:{a2:0 for a2,v2 in alphabet_value_map.items()} for a1,v1 in alphabet_value_map.items()} # v1 - v2\n",
        "        else:\n",
        "            substitution_matrix = {a1:{a2:int(100*(max - abs(v1 - v2))/max) for a2,v2 in alphabet_value_map.items()} for a1,v1 in alphabet_value_map.items()} # v1 - v2\n",
        "        _, score, _ = skbio.alignment.local_pairwise_align_ssw(sequence1=src, sequence2=tgt, substitution_matrix=substitution_matrix, score_size=1, gap_open_penalty=255, gap_extend_penalty=255)\n",
        "        scores += [score / (100 * len(src))]\n",
        "    return np.mean(scores)\n",
        "\n",
        "def pitch_similarity_score(source_wv, stylized_wv):\n",
        "    # extract pitch information from source and stylized wav file\n",
        "    # pitches[f, t] contains instantaneous frequency at bin f, time t, take value 0 at bins of non-maximal magnitude.\n",
        "    source_pitches, _ = librosa.core.piptrack(y=source_wv, sr=sr, n_fft=6*hop, hop_length=hop, fmin=0, fmax=20000.0)   \n",
        "    target_pitches, _ = librosa.core.piptrack(y=stylized_wv, sr=sr, n_fft=6*hop, hop_length=hop, fmin=0, fmax=20000.0)\n",
        "    source_spans = compute_spans(source_pitches)\n",
        "    target_spans = compute_spans(target_pitches)\n",
        "    score = local_matching(source_spans, target_spans)\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48RWB_0LDvRR"
      },
      "source": [
        "# Rythme preservation evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXIkYJ9iOHzW"
      },
      "source": [
        "## Cosine similarity of rythmic envelopes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI465W7yZXQT"
      },
      "source": [
        "From http://dafx.de/paper-archive/2018/papers/DAFx2018_paper_48.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuadeP6XORym"
      },
      "source": [
        "def half_wave_rectifier(x):\n",
        "    return 0.5 * (x + abs(x)) \n",
        "\n",
        "def compute_spectral_flux(spec): # (hop, shape) : (freq, time)\n",
        "    R = []\n",
        "    for t in range(1, spec.shape[1]): # range on time \n",
        "        R += [half_wave_rectifier(abs(next) - abs(prev)) for prev, next in zip(spec[:,t-1], spec[:,t])]\n",
        "    return np.array(R)\n",
        "\n",
        "def to_spec(wav):\n",
        "    d = np.abs(librosa.stft(wav, n_fft=6*hop, hop_length=hop))\n",
        "    db = librosa.amplitude_to_db(d, ref=np.max)\n",
        "    return db\n",
        "\n",
        "def cosine_similarity_spectral_flux_score(source_spec, stylized_spec):\n",
        "    source_spec = to_spec(source_spec)\n",
        "    stylized_spec = to_spec(stylized_spec)\n",
        "    R_source = compute_spectral_flux(source_spec)\n",
        "    R_stylized = compute_spectral_flux(stylized_spec)\n",
        "    return cosine(R_source, R_stylized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am-4bjbPUx7g"
      },
      "source": [
        "# Run evaluation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFbvFwlibNNT"
      },
      "source": [
        "t0 = time.time()\n",
        "\n",
        "x = []\n",
        "for sample, path in zip(samples, paths):\n",
        "    print(path)\n",
        "    a, ab = sample[0], sample[1]\n",
        "    pitch_sim_score = pitch_similarity_score(a, ab)\n",
        "    cosine_spectral_flux_score = cosine_similarity_spectral_flux_score(a, ab)\n",
        "    x += [[path, pitch_cross_correlation_score, pitch_sim_score, cosine_spectral_flux_score]]\n",
        "\n",
        "columns = [\"name\", \"pitch_similarity_score\", \"cosine_spectral_flux_score\"]\n",
        "pd.DataFrame.from_records(x, columns=columns).to_csv(\"dataset/scores/notifications_transfer_objective_evaluations.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}